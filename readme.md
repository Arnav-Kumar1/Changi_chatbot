# ğŸ›¬ Changi & Jewel Airport RAG Chatbot

A **Retrieval-Augmented Generation (RAG)** chatbot for answering queries related to **Changi Airport** and **Jewel Changi** using:

- ğŸ” Dense vector search via **Pinecone**
- ğŸ§  Sparse keyword-based TF-IDF search
- ğŸ¤– **Google Gemini LLM** (via **LangChain**)
- ğŸ› ï¸ Fullstack architecture with **FastAPI (backend)** and **Streamlit (frontend)**
- ğŸ” **BYOK (Bring Your Own Key)** supported â€” users can supply their own Google API key

---

## âš™ï¸ Project Setup & Usage

This project supports **local development**, **Docker-based environments**, and **cloud deployment**.

- ğŸ’» Local setup (recommended for fast iteration)
- ğŸ³ Dockerized setup (recommended for portability and isolation)
- â˜ï¸ Cloud deployment via **Render** and **Streamlit Cloud**

---

## ğŸ§ª 1. Local Setup

### âœ… Prerequisites

- Python 3.10+
- Git (if cloning the repo)
- A terminal that supports virtual environments

### ğŸ› ï¸ Setup Instructions

```bash
# ğŸ“¦ OPTION 1: Clone the repo (recommended)
git clone https://github.com/<your-org>/changi_jewel_rag_chatbot.git
cd changi_jewel_rag_chatbot

# OR

# ğŸ“ OPTION 2: Download ZIP from GitHub
# - Go to the repo page â†’ Click "Code" â†’ "Download ZIP"
# - Extract the folder
# - Then navigate into the extracted directory:
cd changi_jewel_rag_chatbot-main
```

### ğŸ” Create a `.env` file in the project root (see Environment Variables section below)

---

### âš™ï¸ Backend Setup

```bash
# Move into backend directory
cd backend

# Create a virtual environment
python -m venv chatbot_env

# Activate it
# Windows:
chatbot_env\Scripts\activate.bat
# Mac/Linux:
source chatbot_env/bin/activate

# Install backend dependencies
pip install -r requirements_backend.txt
```

### ğŸ“¥ Preprocessing & Embedding

- Run scripts `1_*.py` through `7_*.py` in the `scripts/` folder.
- These will scrape, clean, chunk, embed data, and save vectors to Pinecone.
- After execution, place the following files inside `backend/data/`:
  - `Google_changia_sparse_embs.jsonl`
  - `Google_jewel_sparse_embs.jsonl`

### ğŸš€ Launch Backend

```bash
# From inside backend/ with virtual env active
uvicorn main:app
```

---

### ğŸ¨ Frontend Setup

```bash
# Go back to root
cd ..

# Install frontend requirements
pip install -r requirements_frontend.txt

# Run Streamlit app
streamlit run frontend/frontend.py
```

---

## ğŸ³ 2. Dockerized Setup

### âœ… Prerequisites

- Docker
- Docker Compose

### ğŸ§ª Quickstart

```bash
# Ensure your embedding .jsonl files are in backend/data/
docker-compose up --build
```

- ğŸ“¡ Backend available at: [http://localhost:8000/docs](http://localhost:8000/docs)  
- ğŸ–¥ï¸ Frontend available at: [http://localhost:8501](http://localhost:8501)  
- ğŸ” Live reload supported during development

---

## â˜ï¸ 3. Cloud Deployment

### ğŸš€ Deploy Backend to Render

1. Push your backend code (with Dockerfile) to GitHub
2. Create a **Web Service** on [Render](https://render.com):
   - Environment: **Docker**
   - Root Directory: `backend`
   - Dockerfile Path: `backend/Dockerfile.backend`
3. Add environment variables via Render dashboard
4. Make sure `backend/data/*.jsonl` files are included in the repo or uploaded manually

### ğŸš€ Deploy Frontend

1. Push `frontend.py` and `requirements.txt` to GitHub
2. Deploy using [Streamlit Cloud](https://streamlit.io/cloud):
   - Add **Secrets**: `BACKEND_API_URL`, `GOOGLE_API_KEY`
3. âœ… Alternatively, deploy frontend via Render (Dockerized)

---

## ğŸ”— Connecting Frontend to Backend

In Streamlit secrets or your `.env`, set:

```env
BACKEND_API_URL=https://<your-backend-url>/api/qa
```

---

## ğŸ” Environment Variables

Set the following in a `.env` file or deployment environment:

```env
GOOGLE_API_KEY=your_google_gemini_api_key
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENV=us-west1-gcp
PINECONE_INDEX_NAME=your_index_name
BACKEND_API_URL=http://localhost:8000/api/qa  # For local frontend
```

---

## ğŸ“¡ REST API Reference

- Endpoint: `POST /api/qa`

### ğŸ” Sample Request

```json
{
  "user_query": "How do I get to Changi Airport Terminal 3?",
  "api_key": "optional_google_api_key"
}
```

- Returns: LLM-generated answer and source links

---

## ğŸ§¯ Troubleshooting

- âœ… Ensure `.jsonl` embedding files exist inside `backend/data/`
- ğŸ”‘ Confirm Pinecone API and Google Gemini API keys are valid
- ğŸ“Š Check API usage quotas
- ğŸ” Use Swagger UI at [localhost:8000/docs](http://localhost:8000/docs)
- ğŸ§  Enable logging in `rag_pipeline.py`, `vectorstore.py` for debugging

---

## ğŸ¤ Contributing

1. Fork this repo
2. Clone your fork
3. Set up the project locally (see above)
4. Make improvements with clear commits
5. Open a Pull Request

---

## ğŸ“œ License & Contact

Refer to [`LICENSE`](./LICENSE) or contact the maintainers for support and licensing.

---

**Thanks for using the Changi & Jewel Airport RAG Chatbot!**  
âœˆï¸ *Happy coding and safe travels!*
